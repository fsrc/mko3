// Generated by CoffeeScript 1.10.0
(function() {
  var JsonStream, TokenStream, _, create, js, options, stream, ts,
    extend = function(child, parent) { for (var key in parent) { if (hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; },
    hasProp = {}.hasOwnProperty;

  stream = require("stream");

  _ = require("lodash");

  create = function(TOK) {
    return (function(TOK) {
      var classify, continueToken, createToken, createTokenForType, endToken, isEnding, isExtending, state, tokenize, wrapper;
      wrapper = {};
      classify = function(c) {
        return _.find(TOK, function(def, name) {
          return def.def(c);
        });
      };
      createToken = function(type, data, line, column) {
        var ref;
        return {
          type: type,
          data: data,
          line: line,
          column: column,
          length: (ref = data != null ? data.length : void 0) != null ? ref : 0
        };
      };
      continueToken = function(token, data) {
        var ref;
        return {
          type: token.type,
          data: token.data + data,
          line: token.line,
          column: token.column,
          length: token.length + ((ref = data != null ? data.length : void 0) != null ? ref : 0)
        };
      };
      endToken = function(token) {
        return {
          type: token.type,
          data: TOK[token.type].post(token.data),
          line: token.line,
          column: token.column,
          length: token.length
        };
      };
      isEnding = function(stateType, currType, char) {
        var endsWith;
        endsWith = TOK[stateType].end;
        if (_.isEmpty(endsWith)) {
          return !TOK[stateType].def(char);
        } else {
          return _.includes(endsWith, currType);
        }
      };
      isExtending = function(stateType, currType, char) {
        var endsWith;
        if (TOK[stateType].exto == null) {
          return false;
        } else {
          endsWith = TOK[stateType].end;
          if (_.isEmpty(endsWith)) {
            return !TOK[stateType].def(char) && TOK[TOK[stateType].exto].def(char);
          } else {
            return false;
          }
        }
      };
      createTokenForType = function(type, char, line, column, cb) {
        if (_.includes(TOK.ONE_CHAR_TOKENS, type)) {
          cb(null, createToken(type, char, line, column));
          return null;
        } else if (_.includes(TOK.LONG_TOKENS, type)) {
          return createToken(type, char, line, column);
        } else {
          return createToken(type, char, line, column);
        }
      };
      tokenize = function(state, chunk, cb) {
        return _.reduce(chunk != null ? chunk : [null], function(state, char) {
          var type;
          type = classify(char).id;
          if ((state.token != null) && isExtending(state.token.type, type, char)) {
            state.token.type = TOK[state.token.type].exto;
          }
          if ((state.token != null) && !isEnding(state.token.type, type, char)) {
            state.token = continueToken(state.token, char);
          } else {
            if (state.token != null) {
              if (TOK[state.token.type].incl) {
                state.token = continueToken(state.token, char);
                cb(null, endToken(state.token));
                state.token = null;
              } else {
                cb(null, endToken(state.token));
                state.token = null;
                state.token = createTokenForType(type, char, state.line, state.column, cb);
              }
            } else {
              state.token = createTokenForType(type, char, state.line, state.column, cb);
            }
          }
          if (type === TOK.EOL.id) {
            state.line += 1;
            state.column = 1;
          } else {
            state.column += 1;
          }
          return state;
        }, state);
      };
      state = {
        line: 1,
        column: 1,
        token: null
      };
      wrapper.tokenize = function(chunk, cb) {
        return state = tokenize(state, chunk, cb);
      };
      return wrapper;
    })(TOK);
  };

  TokenStream = (function(superClass) {
    extend(TokenStream, superClass);

    function TokenStream(tokenRules) {
      this.t = create(tokenRules);
      TokenStream.__super__.constructor.call(this, {
        objectMode: true
      });
    }

    TokenStream.prototype._transform = function(chunk, enc, next) {
      this.t.tokenize(chunk.toString(), (function(_this) {
        return function(err, token) {
          if (err != null) {
            return next(err);
          }
          return _this.push(token);
        };
      })(this));
      return next();
    };

    return TokenStream;

  })(stream.Transform);

  if (module.parent != null) {
    module.exports = {
      create: create,
      Stream: TokenStream
    };
  } else {
    JsonStream = require("./json-stream");
    options = require('./common-cli');
    ts = new TokenStream(options.tokenrules);
    js = new JsonStream.Stringify(options.beautify);
    options.instrm.pipe(ts).pipe(js).pipe(options.outstrm);
  }

}).call(this);
